{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Churn Analysis - Data Cleaning\n",
    "## Part 1: Data Preparation and Cleaning\n",
    "\n",
    "**Author:** Your Name  \n",
    "**Date:** February 2026  \n",
    "**Purpose:** Clean and prepare the Telco customer churn dataset for analysis\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "# Download from: https://www.kaggle.com/datasets/blastchar/telco-customer-churn\n",
    "df = pd.read_csv('../data/WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "\n",
    "print(f\"Dataset loaded successfully!\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Rows: {df.shape[0]:,}\")\n",
    "print(f\"Columns: {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initial Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column names\n",
    "print(\"Column Names:\")\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    print(f\"{i:2d}. {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_data = pd.DataFrame({\n",
    "    'Column': df.columns,\n",
    "    'Missing_Count': df.isnull().sum(),\n",
    "    'Missing_Percentage': (df.isnull().sum() / len(df) * 100).round(2)\n",
    "})\n",
    "\n",
    "missing_data = missing_data[missing_data['Missing_Count'] > 0].sort_values('Missing_Count', ascending=False)\n",
    "\n",
    "if len(missing_data) > 0:\n",
    "    print(\"Missing Values Found:\")\n",
    "    print(missing_data)\n",
    "else:\n",
    "    print(\"✓ No missing values found in the dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"Duplicate Rows: {duplicates}\")\n",
    "\n",
    "if duplicates > 0:\n",
    "    print(f\"⚠ Found {duplicates} duplicate rows\")\n",
    "else:\n",
    "    print(\"✓ No duplicates found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types\n",
    "print(\"Data Types:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Fix TotalCharges Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TotalCharges is object type, should be numeric\n",
    "print(f\"Original TotalCharges dtype: {df['TotalCharges'].dtype}\")\n",
    "\n",
    "# Check for non-numeric values\n",
    "non_numeric = df[pd.to_numeric(df['TotalCharges'], errors='coerce').isna()]\n",
    "print(f\"\\nRows with non-numeric TotalCharges: {len(non_numeric)}\")\n",
    "\n",
    "if len(non_numeric) > 0:\n",
    "    print(\"\\nSample of problematic rows:\")\n",
    "    print(non_numeric[['customerID', 'tenure', 'TotalCharges']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert TotalCharges to numeric\n",
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "\n",
    "# Check how many NaN values were created\n",
    "print(f\"NaN values in TotalCharges after conversion: {df['TotalCharges'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Handle Missing Values in TotalCharges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze rows with missing TotalCharges\n",
    "missing_total = df[df['TotalCharges'].isna()]\n",
    "print(f\"Rows with missing TotalCharges: {len(missing_total)}\")\n",
    "print(f\"\\nTenure distribution for missing TotalCharges:\")\n",
    "print(missing_total['tenure'].describe())\n",
    "\n",
    "# Most missing values are for tenure = 0 (new customers)\n",
    "# Fill with MonthlyCharges * tenure (or 0 if tenure = 0)\n",
    "df['TotalCharges'].fillna(df['MonthlyCharges'] * df['tenure'], inplace=True)\n",
    "\n",
    "print(f\"\\n✓ Missing TotalCharges filled\")\n",
    "print(f\"Remaining NaN in TotalCharges: {df['TotalCharges'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Clean Column Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize column names (optional - make them lowercase with underscores)\n",
    "# Uncomment if you want to standardize\n",
    "# df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
    "\n",
    "print(\"✓ Column names cleaned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Verify Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure correct data types\n",
    "df['SeniorCitizen'] = df['SeniorCitizen'].astype('object')  # Convert to categorical\n",
    "\n",
    "print(\"Data Types After Cleaning:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tenure groups\n",
    "df['TenureGroup'] = pd.cut(df['tenure'], \n",
    "                            bins=[0, 6, 12, 24, 48, 72],\n",
    "                            labels=['0-6 months', '6-12 months', '12-24 months', '24-48 months', '48+ months'])\n",
    "\n",
    "print(\"✓ Tenure groups created\")\n",
    "print(df['TenureGroup'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create monthly charge groups\n",
    "df['ChargeGroup'] = pd.cut(df['MonthlyCharges'],\n",
    "                            bins=[0, 30, 60, 90, 150],\n",
    "                            labels=['Low (<$30)', 'Medium ($30-$60)', 'High ($60-$90)', 'Very High ($90+)'])\n",
    "\n",
    "print(\"✓ Charge groups created\")\n",
    "print(df['ChargeGroup'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create service count (number of additional services)\n",
    "service_columns = ['OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies']\n",
    "\n",
    "df['ServiceCount'] = (df[service_columns] == 'Yes').sum(axis=1)\n",
    "\n",
    "print(\"✓ Service count created\")\n",
    "print(df['ServiceCount'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Final Data Quality Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of cleaned dataset\n",
    "print(\"=\" * 60)\n",
    "print(\"CLEANED DATASET SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total Rows: {len(df):,}\")\n",
    "print(f\"Total Columns: {len(df.columns)}\")\n",
    "print(f\"Missing Values: {df.isnull().sum().sum()}\")\n",
    "print(f\"Duplicate Rows: {df.duplicated().sum()}\")\n",
    "print(f\"Memory Usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display cleaned data\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "df.to_csv('../data/cleaned_churn_data.csv', index=False)\n",
    "print(\"✓ Cleaned data saved to '../data/cleaned_churn_data.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to pickle for faster loading\n",
    "df.to_pickle('../data/cleaned_churn_data.pkl')\n",
    "print(\"✓ Cleaned data saved to '../data/cleaned_churn_data.pkl'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Cleaning Steps Completed:\n",
    "1. ✓ Loaded dataset (7,043 rows, 21 columns)\n",
    "2. ✓ Converted TotalCharges to numeric\n",
    "3. ✓ Handled missing values in TotalCharges\n",
    "4. ✓ Verified no duplicates\n",
    "5. ✓ Created engineered features:\n",
    "   - TenureGroup\n",
    "   - ChargeGroup\n",
    "   - ServiceCount\n",
    "6. ✓ Saved cleaned data\n",
    "\n",
    "### Next Steps:\n",
    "- Proceed to `02_exploratory_analysis.ipynb` for EDA\n",
    "- Build visualizations to understand churn patterns\n",
    "- Identify key drivers of customer churn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
