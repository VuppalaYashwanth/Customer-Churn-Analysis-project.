# Setup Instructions

Complete guide to set up and run the Customer Churn Analysis project.

---

## ğŸ“‹ Prerequisites

### Required Software
- **Python 3.8+** - [Download](https://www.python.org/downloads/)
- **MySQL or PostgreSQL** - [MySQL Download](https://dev.mysql.com/downloads/) or [PostgreSQL Download](https://www.postgresql.org/download/)
- **Jupyter Notebook** - Installed via pip
- **Power BI Desktop** - [Download](https://powerbi.microsoft.com/desktop/)
- **Git** - [Download](https://git-scm.com/)

### Optional but Recommended
- **VS Code** - [Download](https://code.visualstudio.com/)
- **DBeaver** or **MySQL Workbench** - For database management
- **Anaconda** - [Download](https://www.anaconda.com/) (includes Jupyter)

---

## ğŸš€ Installation Steps

### 1. Clone the Repository

```bash
# Clone the repository
git clone https://github.com/yourusername/Customer-Churn-Analysis.git

# Navigate to project directory
cd Customer-Churn-Analysis
```

### 2. Set Up Python Environment

#### Option A: Using venv (Recommended)
```bash
# Create virtual environment
python -m venv venv

# Activate virtual environment
# On Windows:
venv\Scripts\activate
# On macOS/Linux:
source venv/bin/activate

# Install dependencies
pip install -r Python/requirements.txt
```

#### Option B: Using Anaconda
```bash
# Create conda environment
conda create -n churn_analysis python=3.8

# Activate environment
conda activate churn_analysis

# Install dependencies
pip install -r Python/requirements.txt
```

### 3. Download Dataset

1. Visit [Kaggle - Telco Customer Churn](https://www.kaggle.com/datasets/blastchar/telco-customer-churn)
2. Download `WA_Fn-UseC_-Telco-Customer-Churn.csv`
3. Place the file in the `data/` directory

```bash
# Your data folder should look like:
data/
â””â”€â”€ WA_Fn-UseC_-Telco-Customer-Churn.csv
```

### 4. Set Up Database (Optional for SQL Practice)

#### MySQL Setup
```sql
-- Connect to MySQL
mysql -u root -p

-- Create database
CREATE DATABASE churn_analysis;

-- Use database
USE churn_analysis;

-- Import data (method 1: using MySQL Workbench)
-- Table > Data Import Wizard > Select CSV file

-- Or (method 2: using command line)
LOAD DATA INFILE '/path/to/WA_Fn-UseC_-Telco-Customer-Churn.csv'
INTO TABLE customers
FIELDS TERMINATED BY ','
ENCLOSED BY '"'
LINES TERMINATED BY '\n'
IGNORE 1 ROWS;
```

#### PostgreSQL Setup
```sql
-- Connect to PostgreSQL
psql -U postgres

-- Create database
CREATE DATABASE churn_analysis;

-- Connect to database
\c churn_analysis

-- Create table and import data
-- (Use pgAdmin or DBeaver for easier import)
```

---

## ğŸ¯ Running the Project

### Step 1: SQL Analysis (Optional)

```bash
# Navigate to SQL directory
cd SQL

# Run queries in your database client
# Execute in order:
# 1. 01_data_extraction.sql
# 2. 02_churn_analysis.sql
# 3. 03_customer_segmentation.sql
```

### Step 2: Python Analysis

```bash
# Start Jupyter Notebook
jupyter notebook

# Navigate to Python folder and run notebooks in order:
# 1. 01_data_cleaning.ipynb
# 2. 02_exploratory_analysis.ipynb
# 3. 03_churn_prediction.ipynb
```

#### Or run from command line:
```bash
cd Python

# Convert notebooks to Python scripts
jupyter nbconvert --to script 01_data_cleaning.ipynb

# Run the script
python 01_data_cleaning.py
```

### Step 3: Power BI Dashboard

1. Open Power BI Desktop
2. Click **Get Data** â†’ **Text/CSV**
3. Load `data/cleaned_churn_data.csv`
4. Follow instructions in `PowerBI/Dashboard_Creation_Guide.md`
5. Import DAX measures from `PowerBI/DAX_measures.txt`
6. Create visualizations as described

---

## ğŸ”§ Configuration

### Database Configuration

Create a `.env` file in the root directory:

```env
# Database Configuration
DB_HOST=localhost
DB_PORT=3306
DB_NAME=churn_analysis
DB_USER=root
DB_PASSWORD=your_password
```

### Python Configuration

Update database connection in Python scripts if needed:

```python
import os
from dotenv import load_dotenv
import pymysql

load_dotenv()

# Database connection
connection = pymysql.connect(
    host=os.getenv('DB_HOST'),
    port=int(os.getenv('DB_PORT')),
    user=os.getenv('DB_USER'),
    password=os.getenv('DB_PASSWORD'),
    database=os.getenv('DB_NAME')
)
```

---

## ğŸ“Š Project Workflow

```
1. Data Collection
   â””â”€â”€ Download dataset from Kaggle
   
2. SQL Analysis (Optional)
   â”œâ”€â”€ Import data to database
   â”œâ”€â”€ Run extraction queries
   â”œâ”€â”€ Analyze churn patterns
   â””â”€â”€ Create customer segments
   
3. Python Analysis
   â”œâ”€â”€ Data cleaning
   â”œâ”€â”€ Exploratory analysis
   â”œâ”€â”€ Feature engineering
   â””â”€â”€ Build ML models
   
4. Power BI Dashboard
   â”œâ”€â”€ Import cleaned data
   â”œâ”€â”€ Create DAX measures
   â”œâ”€â”€ Build visualizations
   â””â”€â”€ Publish dashboard
   
5. Documentation
   â””â”€â”€ Update README with findings
```

---

## ğŸ§ª Testing

### Verify Installation

```bash
# Test Python packages
python -c "import pandas, numpy, sklearn, matplotlib, seaborn; print('All packages installed!')"

# Test Jupyter
jupyter notebook --version

# Test database connection
python -c "import pymysql; print('PyMySQL installed!')"
```

### Run Quick Test

```python
# test_setup.py
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split

print("âœ“ All imports successful!")

# Load data
try:
    df = pd.read_csv('data/WA_Fn-UseC_-Telco-Customer-Churn.csv')
    print(f"âœ“ Dataset loaded: {df.shape}")
except:
    print("âœ— Dataset not found. Please download it.")
```

---

## ğŸ› Troubleshooting

### Common Issues

#### Issue 1: "Module not found"
```bash
# Solution: Install missing package
pip install <package-name>
```

#### Issue 2: "Permission denied" on macOS/Linux
```bash
# Solution: Add execute permission
chmod +x script_name.py
```

#### Issue 3: "VCRUNTIME140.dll missing" on Windows
```bash
# Solution: Install Visual C++ Redistributable
# Download from Microsoft website
```

#### Issue 4: Jupyter notebook won't start
```bash
# Solution: Reinstall Jupyter
pip uninstall jupyter
pip install jupyter
```

#### Issue 5: Database connection error
```bash
# Solution: Check credentials and service status
# MySQL:
sudo service mysql status
# PostgreSQL:
sudo service postgresql status
```

### Getting Help

1. Check [Issues](https://github.com/yourusername/Customer-Churn-Analysis/issues)
2. Review documentation in `docs/` folder
3. Reach out via email or LinkedIn

---

## ğŸ“ Directory Structure After Setup

```
Customer-Churn-Analysis/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ WA_Fn-UseC_-Telco-Customer-Churn.csv    # Original data
â”‚   â”œâ”€â”€ cleaned_churn_data.csv                   # Generated after cleaning
â”‚   â””â”€â”€ cleaned_churn_data.pkl                   # Generated after cleaning
â”‚
â”œâ”€â”€ Python/
â”‚   â”œâ”€â”€ 01_data_cleaning.ipynb
â”‚   â”œâ”€â”€ 02_exploratory_analysis.ipynb
â”‚   â”œâ”€â”€ 03_churn_prediction.ipynb
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ SQL/
â”‚   â”œâ”€â”€ 01_data_extraction.sql
â”‚   â”œâ”€â”€ 02_churn_analysis.sql
â”‚   â””â”€â”€ 03_customer_segmentation.sql
â”‚
â”œâ”€â”€ PowerBI/
â”‚   â”œâ”€â”€ churn_dashboard.pbix                     # Created by you
â”‚   â”œâ”€â”€ DAX_measures.txt
â”‚   â””â”€â”€ Dashboard_Creation_Guide.md
â”‚
â”œâ”€â”€ images/                                       # Generated by notebooks
â”‚   â”œâ”€â”€ overall_churn_distribution.png
â”‚   â”œâ”€â”€ contract_type_analysis.png
â”‚   â””â”€â”€ ... (other visualizations)
â”‚
â”œâ”€â”€ models/                                       # Generated by ML notebook
â”‚   â”œâ”€â”€ random_forest_churn_model.pkl
â”‚   â””â”€â”€ scaler.pkl
â”‚
â”œâ”€â”€ .gitignore
â”œâ”€â”€ LICENSE
â”œâ”€â”€ README.md
â””â”€â”€ SETUP.md                                     # This file
```

---

## âœ… Verification Checklist

- [ ] Python 3.8+ installed
- [ ] All Python packages installed
- [ ] Dataset downloaded
- [ ] Jupyter Notebook running
- [ ] Database setup (optional)
- [ ] Power BI Desktop installed
- [ ] Git configured
- [ ] Test script runs successfully

---

## ğŸ“ Next Steps

1. âœ“ Complete setup
2. Run `01_data_cleaning.ipynb`
3. Run `02_exploratory_analysis.ipynb`
4. Run `03_churn_prediction.ipynb`
5. Create Power BI dashboard
6. Document findings
7. Update README with results
8. Share on GitHub/LinkedIn

---

## ğŸ“ Support

**Project Maintainer:** Your Name  
**Email:** your.email@example.com  
**LinkedIn:** [Your LinkedIn Profile](https://linkedin.com/in/yourprofile)

---

**Happy Analyzing! ğŸ“Š**
